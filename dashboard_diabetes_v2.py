
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

st.set_page_config(page_title="Dashboard Ultra Pro - Diabetes", layout="wide")

st.title("üß† Dashboard Avan√ßado de An√°lise de Diabetes")
st.markdown("An√°lise completa de dados, modelos de machine learning e insights estrat√©gicos sobre a base de Diabetes do Kaggle.")

uploaded_file = st.file_uploader("Fa√ßa upload do arquivo diabetes.csv", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    st.sidebar.header("Configura√ß√µes")
    model_select = st.sidebar.selectbox("Escolha o Modelo para An√°lises:", ["Regress√£o Log√≠stica", "Random Forest", "KNN", "SVM"])

    st.header("üìä Vis√£o Geral dos Dados")
    st.dataframe(df.describe())

    cols_to_fix = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
    df_cleaned = df.copy()
    for col in cols_to_fix:
        median_val = df_cleaned[col].median()
        df_cleaned[col] = df_cleaned[col].replace(0, median_val)

    X = df_cleaned.drop(columns=["Outcome"])
    y = df_cleaned["Outcome"]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

    models = {
        "Regress√£o Log√≠stica": LogisticRegression(max_iter=1000),
        "Random Forest": RandomForestClassifier(random_state=42),
        "KNN": KNeighborsClassifier(),
        "SVM": SVC(probability=True)
    }

    results = {}
    conf_matrices = {}
    reports = {}

    for name, model in models.items():
        model.fit(X_train, y_train)
        preds = model.predict(X_test)
        acc = np.round((preds == y_test).mean(), 4)
        results[name] = acc
        conf_matrices[name] = confusion_matrix(y_test, preds)
        reports[name] = classification_report(y_test, preds, output_dict=True)

    # Random Forest para Feature Importance
    rf_model = RandomForestClassifier(random_state=42)
    rf_model.fit(X_train, y_train)
    feature_importance = pd.DataFrame({
        'Feature': df_cleaned.drop(columns=['Outcome']).columns,
        'Importance': rf_model.feature_importances_
    }).sort_values(by='Importance', ascending=False)

    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
        "üìà Acur√°cia dos Modelos",
        "üîó Matriz de Correla√ß√£o",
        "üß© Matrizes de Confus√£o",
        "üí° Insights e Conclus√µes",
        "üèÜ Import√¢ncia das Vari√°veis",
        "üìã M√©tricas do Modelo"
    ])

    with tab1:
        st.subheader("Compara√ß√£o de Acur√°cia entre os Modelos")
        acc_df = pd.DataFrame.from_dict(results, orient="index", columns=["Acur√°cia"]).sort_values(by="Acur√°cia", ascending=False)
        st.bar_chart(acc_df)

    with tab2:
        st.subheader("Matriz de Correla√ß√£o das Vari√°veis")
        fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
        sns.heatmap(df_cleaned.corr(), annot=True, cmap="coolwarm", square=True, ax=ax_corr)
        st.pyplot(fig_corr)

    with tab3:
        st.subheader("Matrizes de Confus√£o por Modelo")
        for name, matrix in conf_matrices.items():
            st.markdown(f"**{name}**")
            fig_cm, ax_cm = plt.subplots()
            disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=["N√£o Diab√©tico", "Diab√©tico"])
            disp.plot(ax=ax_cm, cmap="Blues", values_format="d")
            plt.grid(False)
            st.pyplot(fig_cm)

    with tab4:
        st.subheader("Principais Insights Estrat√©gicos")
        insights = {
            "üîπ Glicose alta √© o principal indicador de risco.": "Altos n√≠veis de glicose no plasma est√£o fortemente associados ao diagn√≥stico positivo de diabetes.",
            "üîπ IMC elevado √© um fator importante.": "Pacientes com BMI acima de 30 t√™m maior risco de desenvolver diabetes.",
            "üîπ Idade impacta o risco.": "O risco de diabetes aumenta significativamente a partir dos 40 anos.",
            "üîπ Hist√≥rico familiar influencia.": "A fun√ß√£o de pedigree para diabetes tamb√©m impacta a chance de diagn√≥stico, mas com menor peso."
        }
        for k, v in insights.items():
            st.success(f"{k}\n\n{v}")


    with tab5:
        st.subheader("Import√¢ncia das Vari√°veis")
        fig_imp, ax_imp = plt.subplots(figsize=(8, 6))
        sns.barplot(x="Importance", y="Feature", data=feature_importance, palette="viridis", ax=ax_imp)
        st.pyplot(fig_imp)

    with tab6:
        st.subheader(f"M√©tricas do Modelo: {model_select}")
        selected_report = reports[model_select]
        col1, col2, col3 = st.columns(3)
        col1.metric("Acur√°cia", f"{selected_report['accuracy']*100:.2f}%")
        col2.metric("Recall (Detec√ß√£o)", f"{selected_report['1']['recall']*100:.2f}%")
        col3.metric("Precis√£o", f"{selected_report['1']['precision']*100:.2f}%")

    st.markdown("---")
    st.caption("Feito com ‚ù§Ô∏è usando Streamlit.")

else:
    st.info("Por favor, carregue o arquivo diabetes.csv para visualizar o dashboard.")
